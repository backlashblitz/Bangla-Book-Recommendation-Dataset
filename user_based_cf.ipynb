{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Set\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Utility Loader\n",
    "# ---------------------------------------\n",
    "\n",
    "def load_json(path: str):\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedCFRecommender():\n",
    "    \"\"\"\n",
    "    User-based kNN Collaborative Filtering using SPARSE cosine similarity.\n",
    "    Trained only on train_user_book interactions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_user_book: Dict[str, List[str]], k_neighbors: int = 50):\n",
    "        # Deduplicate interactions\n",
    "        self.train_user_book = {u: list(set(books)) for u, books in train_user_book.items()}\n",
    "        self.k_neighbors = k_neighbors\n",
    "\n",
    "        self.user_ids = []\n",
    "        self.book_ids = []\n",
    "        self.user_id_map = {}\n",
    "        self.book_id_map = {}\n",
    "        self.interaction_matrix = None\n",
    "        self.user_sim_matrix = None\n",
    "\n",
    "    def fit(self):\n",
    "        print(\"Building User-Based CF (Sparse, train-only)...\")\n",
    "\n",
    "        user_book = self.train_user_book\n",
    "\n",
    "        # Collect ids\n",
    "        self.user_ids = sorted(user_book.keys())\n",
    "        self.book_ids = sorted({b for books in user_book.values() for b in books})\n",
    "\n",
    "        self.user_id_map = {u: i for i, u in enumerate(self.user_ids)}\n",
    "        self.book_id_map = {b: i for i, b in enumerate(self.book_ids)}\n",
    "\n",
    "        # Build sparse interaction matrix\n",
    "        rows, cols = [], []\n",
    "        print(\"Building sparse interaction matrix...\")\n",
    "        for u, books in tqdm(user_book.items()):\n",
    "            ui = self.user_id_map[u]\n",
    "            for b in books:\n",
    "                bi = self.book_id_map[b]\n",
    "                rows.append(ui)\n",
    "                cols.append(bi)\n",
    "\n",
    "        data = np.ones(len(rows), dtype=np.float32)\n",
    "        self.interaction_matrix = csr_matrix(\n",
    "            (data, (rows, cols)),\n",
    "            shape=(len(self.user_ids), len(self.book_ids)),\n",
    "        )\n",
    "\n",
    "        # User-user cosine similarity\n",
    "        print(\"Computing user-user similarity (this may take 1–3 minutes)...\")\n",
    "        self.user_sim_matrix = cosine_similarity(\n",
    "            self.interaction_matrix, dense_output=False\n",
    "        )\n",
    "\n",
    "    def recommend(self, user_id: str, k: int = 10):\n",
    "        if user_id not in self.user_id_map:\n",
    "            return []\n",
    "\n",
    "        uidx = self.user_id_map[user_id]\n",
    "        user_sim = self.user_sim_matrix.getrow(uidx).toarray().ravel()\n",
    "\n",
    "        # k nearest neighbours (excluding self)\n",
    "        neighbor_idxs = np.argsort(user_sim)[::-1][1 : self.k_neighbors + 1]\n",
    "\n",
    "        scores = np.zeros(len(self.book_ids), dtype=np.float32)\n",
    "        for nidx in neighbor_idxs:\n",
    "            scores += self.interaction_matrix.getrow(nidx).toarray().ravel()\n",
    "\n",
    "        # Filter out items already seen in TRAIN\n",
    "        seen = self.interaction_matrix.getrow(uidx).toarray().ravel() > 0\n",
    "        scores[seen] = -1\n",
    "\n",
    "        top_items = np.argsort(scores)[::-1][:k]\n",
    "        return [self.book_ids[i] for i in top_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "evaluator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluates ranking-based recommendation metrics.\n",
    "    Computes: Hit@K, MRR@K, NDCG@K for various K values.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def hit_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
    "        \"\"\"\n",
    "        Hit@K: 1 if at least one relevant item is in top-K, else 0\n",
    "        \"\"\"\n",
    "        top_k = predictions[:k]\n",
    "        return 1.0 if any(item in ground_truth for item in top_k) else 0.0\n",
    "    \n",
    "    def mrr_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
    "        \"\"\"\n",
    "        MRR@K: Reciprocal rank of first relevant item in top-K\n",
    "        \"\"\"\n",
    "        top_k = predictions[:k]\n",
    "        for rank, item in enumerate(top_k, start=1):\n",
    "            if item in ground_truth:\n",
    "                return 1.0 / rank\n",
    "        return 0.0\n",
    "    \n",
    "    def dcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
    "        \"\"\"\n",
    "        DCG@K: Discounted Cumulative Gain\n",
    "        \"\"\"\n",
    "        dcg = 0.0\n",
    "        top_k = predictions[:k]\n",
    "        for rank, item in enumerate(top_k, start=1):\n",
    "            if item in ground_truth:\n",
    "                dcg += 1.0 / np.log2(rank + 1)\n",
    "        return dcg\n",
    "    \n",
    "    def idcg_at_k(self, ground_truth: Set[str], k: int) -> float:\n",
    "        \"\"\"\n",
    "        IDCG@K: Ideal DCG (best possible DCG)\n",
    "        \"\"\"\n",
    "        ideal_k = min(len(ground_truth), k)\n",
    "        idcg = sum(1.0 / np.log2(rank + 1) for rank in range(1, ideal_k + 1))\n",
    "        return idcg\n",
    "    \n",
    "    def ndcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
    "        \"\"\"\n",
    "        NDCG@K: Normalized Discounted Cumulative Gain\n",
    "        \"\"\"\n",
    "        dcg = self.dcg_at_k(predictions, ground_truth, k)\n",
    "        idcg = self.idcg_at_k(ground_truth, k)\n",
    "        \n",
    "        if idcg == 0.0:\n",
    "            return 0.0\n",
    "        \n",
    "        return dcg / idcg\n",
    "    \n",
    "    def evaluate(self, predictions: Dict[str, List[str]], ground_truth: Dict[str, Set[str]]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Evaluate predictions against ground truth.\n",
    "        \n",
    "        Args:\n",
    "            predictions: Dict mapping user_id -> list of recommended item_ids (ranked)\n",
    "            ground_truth: Dict mapping user_id -> set of relevant item_ids\n",
    "            \n",
    "        Returns:\n",
    "            Dict of metric_name -> average_score\n",
    "        \"\"\"\n",
    "        metrics = {\n",
    "            'Hit@5': [],\n",
    "            'Hit@10': [],\n",
    "            'Hit@50': [],\n",
    "            'MRR@10': [],\n",
    "            'NDCG@10': [],\n",
    "            'NDCG@50': []\n",
    "        }\n",
    "        \n",
    "        # Only evaluate users present in both predictions and ground_truth\n",
    "        common_users = set(predictions.keys()) & set(ground_truth.keys())\n",
    "        \n",
    "        for user_id in common_users:\n",
    "            preds = predictions[user_id]\n",
    "            gt = ground_truth[user_id]\n",
    "            \n",
    "            # Skip users with no ground truth items\n",
    "            if len(gt) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Compute metrics\n",
    "            metrics['Hit@5'].append(self.hit_at_k(preds, gt, 5))\n",
    "            metrics['Hit@10'].append(self.hit_at_k(preds, gt, 10))\n",
    "            metrics['Hit@50'].append(self.hit_at_k(preds, gt, 50))\n",
    "            metrics['MRR@10'].append(self.mrr_at_k(preds, gt, 10))\n",
    "            metrics['NDCG@10'].append(self.ndcg_at_k(preds, gt, 10))\n",
    "            metrics['NDCG@50'].append(self.ndcg_at_k(preds, gt, 50))\n",
    "        \n",
    "        # Average across all users\n",
    "        results = {}\n",
    "        for metric_name, values in metrics.items():\n",
    "            if len(values) > 0:\n",
    "                results[metric_name] = np.mean(values)\n",
    "            else:\n",
    "                results[metric_name] = 0.0\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_book_interactions(\n",
    "    user_to_review_path: str,\n",
    "    book_to_review_path: str,\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Builds:\n",
    "        user_id -> [book_id, book_id, ...]\n",
    "    \"\"\"\n",
    "    user_to_review = load_json(user_to_review_path)\n",
    "    book_to_review = load_json(book_to_review_path)\n",
    "\n",
    "    # Normalize IDs to string\n",
    "    review_to_user = {\n",
    "        str(x[\"review_id\"]): str(x[\"user_id\"])\n",
    "        for x in user_to_review\n",
    "    }\n",
    "\n",
    "    review_to_book = {\n",
    "        str(x[\"review_id\"]): str(x[\"book_id\"])\n",
    "        for x in book_to_review\n",
    "    }\n",
    "\n",
    "    user_book = defaultdict(list)\n",
    "\n",
    "    for rid, user_id in review_to_user.items():\n",
    "        if rid in review_to_book:\n",
    "            book_id = review_to_book[rid]\n",
    "            user_book[user_id].append(book_id)\n",
    "\n",
    "    return user_book\n",
    "\n",
    "\n",
    "def split_user_interactions(\n",
    "    user_book: Dict[str, List[str]],\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        train_user_book\n",
    "        val_user_book\n",
    "        test_user_book\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    train = {}\n",
    "    val = {}\n",
    "    test = {}\n",
    "\n",
    "    for user, books in user_book.items():\n",
    "        books = list(set(books))  # remove duplicates\n",
    "        random.shuffle(books)\n",
    "\n",
    "        n = len(books)\n",
    "        if n < 3:\n",
    "            train[user] = books\n",
    "            val[user] = []\n",
    "            test[user] = []\n",
    "            continue\n",
    "\n",
    "        n_train = int(0.7 * n)\n",
    "        n_val = int(0.15 * n)\n",
    "\n",
    "        train[user] = books[:n_train]\n",
    "        val[user] = books[n_train : n_train + n_val]\n",
    "        test[user] = books[n_train + n_val :]\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def build_ground_truth(test_user_book: Dict[str, List[str]]) -> Dict[str, Set[str]]:\n",
    "    return {\n",
    "        user: set(books)\n",
    "        for user, books in test_user_book.items()\n",
    "        if len(books) > 0\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_predictions(model, users: List[str], k: int):\n",
    "    predictions = {}\n",
    "\n",
    "    for u in tqdm(users, desc=\"Generating Predictions\"):\n",
    "        preds = model.recommend(u, k)\n",
    "        predictions[u] = preds\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "main",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users with interactions: 63721\n",
      "Users in test set: 15427\n",
      "\n",
      "Training User-Based CF...\n",
      "Building User-Based CF (Sparse, train-only)...\n",
      "Building sparse interaction matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 63721/63721 [00:00<00:00, 1012698.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user-user similarity (this may take 1–3 minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Predictions: 100%|███████████████████████████████████████████████████| 15427/15427 [01:14<00:00, 205.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== User-Based CF Results =====\n",
      "Hit@5: 0.1009\n",
      "Hit@10: 0.1235\n",
      "Hit@50: 0.1235\n",
      "MRR@10: 0.0749\n",
      "NDCG@10: 0.0659\n",
      "NDCG@50: 0.0657\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # -------------------------------\n",
    "    # Paths\n",
    "    # -------------------------------\n",
    "\n",
    "    DATA_FOLDER = \"RokomariBG_Dataset/\"\n",
    "    USER_TO_REVIEW = DATA_FOLDER+\"user_to_review.json.gz\"\n",
    "    BOOK_TO_REVIEW = DATA_FOLDER+\"book_to_review.json.gz\"\n",
    "\n",
    "    K = 10\n",
    "\n",
    "    # -------------------------------\n",
    "    # Build user-book interactions\n",
    "    # -------------------------------\n",
    "    user_book = build_user_book_interactions(\n",
    "        USER_TO_REVIEW,\n",
    "        BOOK_TO_REVIEW,\n",
    "    )\n",
    "\n",
    "    print(f\"Total users with interactions: {len(user_book)}\")\n",
    "\n",
    "    evaluator = RankingEvaluator()\n",
    "\n",
    "    # -------------------------------\n",
    "    # Split 70/15/15\n",
    "    # -------------------------------\n",
    "    train_user_book, val_user_book, test_user_book = split_user_interactions(\n",
    "        user_book\n",
    "    )\n",
    "\n",
    "    ground_truth = build_ground_truth(test_user_book)\n",
    "    test_users = list(ground_truth.keys())\n",
    "\n",
    "    print(f\"Users in test set: {len(test_users)}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # USER-BASED CF\n",
    "    # =====================================================\n",
    "\n",
    "    print(\"\\nTraining User-Based CF...\")\n",
    "\n",
    "    user_cf = UserBasedCFRecommender(\n",
    "        train_user_book=train_user_book,\n",
    "        k_neighbors=50,\n",
    "    )\n",
    "    user_cf.fit()\n",
    "\n",
    "    user_cf_preds = generate_predictions(user_cf, test_users, K)\n",
    "    user_cf_metrics = evaluator.evaluate(user_cf_preds, ground_truth)\n",
    "\n",
    "    print(\"\\n===== User-Based CF Results =====\")\n",
    "    for m, v in user_cf_metrics.items():\n",
    "        print(f\"{m}: {v:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204dc91-b9b6-44b7-8ac8-f6f1234726e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
