{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Set\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Utility Loader\n",
    "# ---------------------------------------\n",
    "\n",
    "def load_json(path: str):\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedCFRecommender():\n",
    "    \"\"\"\n",
    "    User-based kNN Collaborative Filtering using SPARSE cosine similarity.\n",
    "    Trained only on train_user_book interactions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_user_book: Dict[str, List[str]], k_neighbors: int = 50):\n",
    "        # Deduplicate interactions\n",
    "        self.train_user_book = {u: list(set(books)) for u, books in train_user_book.items()}\n",
    "        self.k_neighbors = k_neighbors\n",
    "\n",
    "        self.user_ids = []\n",
    "        self.book_ids = []\n",
    "        self.user_id_map = {}\n",
    "        self.book_id_map = {}\n",
    "        self.interaction_matrix = None\n",
    "        self.user_sim_matrix = None\n",
    "\n",
    "    def fit(self):\n",
    "        print(\"Building User-Based CF (Sparse, train-only)...\")\n",
    "\n",
    "        user_book = self.train_user_book\n",
    "\n",
    "        # Collect ids\n",
    "        self.user_ids = sorted(user_book.keys())\n",
    "        self.book_ids = sorted({b for books in user_book.values() for b in books})\n",
    "\n",
    "        self.user_id_map = {u: i for i, u in enumerate(self.user_ids)}\n",
    "        self.book_id_map = {b: i for i, b in enumerate(self.book_ids)}\n",
    "\n",
    "        # Build sparse interaction matrix\n",
    "        rows, cols = [], []\n",
    "        print(\"Building sparse interaction matrix...\")\n",
    "        for u, books in tqdm(user_book.items()):\n",
    "            ui = self.user_id_map[u]\n",
    "            for b in books:\n",
    "                bi = self.book_id_map[b]\n",
    "                rows.append(ui)\n",
    "                cols.append(bi)\n",
    "\n",
    "        data = np.ones(len(rows), dtype=np.float32)\n",
    "        self.interaction_matrix = csr_matrix(\n",
    "            (data, (rows, cols)),\n",
    "            shape=(len(self.user_ids), len(self.book_ids)),\n",
    "        )\n",
    "\n",
    "        # User-user cosine similarity\n",
    "        print(\"Computing user-user similarity (this may take 1–3 minutes)...\")\n",
    "        self.user_sim_matrix = cosine_similarity(\n",
    "            self.interaction_matrix, dense_output=False\n",
    "        )\n",
    "\n",
    "    def recommend(self, user_id: str, k: int = 10):\n",
    "        if user_id not in self.user_id_map:\n",
    "            return []\n",
    "\n",
    "        uidx = self.user_id_map[user_id]\n",
    "        user_sim = self.user_sim_matrix.getrow(uidx).toarray().ravel()\n",
    "\n",
    "        # k nearest neighbours (excluding self)\n",
    "        neighbor_idxs = np.argsort(user_sim)[::-1][1 : self.k_neighbors + 1]\n",
    "\n",
    "        scores = np.zeros(len(self.book_ids), dtype=np.float32)\n",
    "        for nidx in neighbor_idxs:\n",
    "            scores += self.interaction_matrix.getrow(nidx).toarray().ravel()\n",
    "\n",
    "        # Filter out items already seen in TRAIN\n",
    "        seen = self.interaction_matrix.getrow(uidx).toarray().ravel() > 0\n",
    "        scores[seen] = -1\n",
    "\n",
    "        top_items = np.argsort(scores)[::-1][:k]\n",
    "        return [self.book_ids[i] for i in top_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "evaluator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluation class for Top-N Recommendation.\n",
    "\n",
    "    Supports:\n",
    "        - Hit@K\n",
    "        - MRR@K\n",
    "        - NDCG@K\n",
    "\n",
    "    Input format:\n",
    "        predictions: Dict[user_id, List[item_id]]\n",
    "        ground_truth: Dict[user_id, Set[item_id]]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: int = 10):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Cutoff rank for evaluation (e.g., 5, 10, 20)\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "\n",
    "    # -------------------------\n",
    "    # Hit@K\n",
    "    # -------------------------\n",
    "    def hit_at_k(self, predictions: Dict, ground_truth: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Computes Hit@K\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float : Average Hit@K over users\n",
    "        \"\"\"\n",
    "        hits = []\n",
    "\n",
    "        for user in ground_truth:\n",
    "            if user not in predictions:\n",
    "                continue\n",
    "\n",
    "            top_k = predictions[user][:self.k]\n",
    "            gt_items = ground_truth[user]\n",
    "\n",
    "            hit = 1.0 if any(item in gt_items for item in top_k) else 0.0\n",
    "            hits.append(hit)\n",
    "\n",
    "        return float(np.mean(hits)) if hits else 0.0\n",
    "\n",
    "    # -------------------------\n",
    "    # MRR@K\n",
    "    # -------------------------\n",
    "    def mrr_at_k(self, predictions: Dict, ground_truth: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Computes Mean Reciprocal Rank (MRR@K)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float : Average MRR over users\n",
    "        \"\"\"\n",
    "        rr_scores = []\n",
    "\n",
    "        for user in ground_truth:\n",
    "            if user not in predictions:\n",
    "                continue\n",
    "\n",
    "            top_k = predictions[user][:self.k]\n",
    "            gt_items = ground_truth[user]\n",
    "\n",
    "            rr = 0.0\n",
    "            for rank, item in enumerate(top_k, start=1):\n",
    "                if item in gt_items:\n",
    "                    rr = 1.0 / rank\n",
    "                    break\n",
    "\n",
    "            rr_scores.append(rr)\n",
    "\n",
    "        return float(np.mean(rr_scores)) if rr_scores else 0.0\n",
    "\n",
    "    # -------------------------\n",
    "    # NDCG@K\n",
    "    # -------------------------\n",
    "    def ndcg_at_k(self, predictions: Dict, ground_truth: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Computes Normalized Discounted Cumulative Gain (NDCG@K)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float : Average NDCG@K over users\n",
    "        \"\"\"\n",
    "        ndcg_scores = []\n",
    "\n",
    "        for user in tqdm(ground_truth, desc=\"Evaluating\"):\n",
    "            if user not in predictions:\n",
    "                continue\n",
    "\n",
    "            top_k = predictions[user][:self.k]\n",
    "            gt_items = ground_truth[user]\n",
    "\n",
    "            dcg = 0.0\n",
    "            for i, item in enumerate(top_k):\n",
    "                if item in gt_items:\n",
    "                    dcg += 1.0 / math.log2(i + 2)\n",
    "\n",
    "            ideal_hits = min(len(gt_items), self.k)\n",
    "            idcg = sum(1.0 / math.log2(i + 2) for i in range(ideal_hits))\n",
    "\n",
    "            ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "        return float(np.mean(ndcg_scores)) if ndcg_scores else 0.0\n",
    "\n",
    "    # -------------------------\n",
    "    # Combined Evaluation\n",
    "    # -------------------------\n",
    "    def evaluate(self, predictions: Dict, ground_truth: Dict) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Computes all metrics together.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, float]\n",
    "        \"\"\"\n",
    "        return {\n",
    "            f\"Hit@{self.k}\": self.hit_at_k(predictions, ground_truth),\n",
    "            f\"MRR@{self.k}\": self.mrr_at_k(predictions, ground_truth),\n",
    "            f\"NDCG@{self.k}\": self.ndcg_at_k(predictions, ground_truth),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_book_interactions(\n",
    "    user_to_review_path: str,\n",
    "    book_to_review_path: str,\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Builds:\n",
    "        user_id -> [book_id, book_id, ...]\n",
    "    \"\"\"\n",
    "    user_to_review = load_json(user_to_review_path)\n",
    "    book_to_review = load_json(book_to_review_path)\n",
    "\n",
    "    # Normalize IDs to string\n",
    "    review_to_user = {\n",
    "        str(x[\"review_id\"]): str(x[\"user_id\"])\n",
    "        for x in user_to_review\n",
    "    }\n",
    "\n",
    "    review_to_book = {\n",
    "        str(x[\"review_id\"]): str(x[\"book_id\"])\n",
    "        for x in book_to_review\n",
    "    }\n",
    "\n",
    "    user_book = defaultdict(list)\n",
    "\n",
    "    for rid, user_id in review_to_user.items():\n",
    "        if rid in review_to_book:\n",
    "            book_id = review_to_book[rid]\n",
    "            user_book[user_id].append(book_id)\n",
    "\n",
    "    return user_book\n",
    "\n",
    "\n",
    "def split_user_interactions(\n",
    "    user_book: Dict[str, List[str]],\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        train_user_book\n",
    "        val_user_book\n",
    "        test_user_book\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    train = {}\n",
    "    val = {}\n",
    "    test = {}\n",
    "\n",
    "    for user, books in user_book.items():\n",
    "        books = list(set(books))  # remove duplicates\n",
    "        random.shuffle(books)\n",
    "\n",
    "        n = len(books)\n",
    "        if n < 3:\n",
    "            train[user] = books\n",
    "            val[user] = []\n",
    "            test[user] = []\n",
    "            continue\n",
    "\n",
    "        n_train = int(0.7 * n)\n",
    "        n_val = int(0.15 * n)\n",
    "\n",
    "        train[user] = books[:n_train]\n",
    "        val[user] = books[n_train : n_train + n_val]\n",
    "        test[user] = books[n_train + n_val :]\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def build_ground_truth(test_user_book: Dict[str, List[str]]) -> Dict[str, Set[str]]:\n",
    "    return {\n",
    "        user: set(books)\n",
    "        for user, books in test_user_book.items()\n",
    "        if len(books) > 0\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_predictions(model, users: List[str], k: int):\n",
    "    predictions = {}\n",
    "\n",
    "    for u in tqdm(users, desc=\"Generating Predictions\"):\n",
    "        preds = model.recommend(u, k)\n",
    "        predictions[u] = preds\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "main",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users with interactions: 63721\n",
      "Users in test set: 15427\n",
      "\n",
      "Training User-Based CF...\n",
      "Building User-Based CF (Sparse, train-only)...\n",
      "Building sparse interaction matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 63721/63721 [00:00<00:00, 453603.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user-user similarity (this may take 1–3 minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|███████████████████████████████████████████████████| 15427/15427 [01:15<00:00, 203.57it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████| 15427/15427 [00:00<00:00, 287713.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== User-Based CF Results =====\n",
      "Hit@10: 0.1215\n",
      "MRR@10: 0.0709\n",
      "NDCG@10: 0.0631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # -------------------------------\n",
    "    # Paths\n",
    "    # -------------------------------\n",
    "    DATA_FOLDER = r\"E:/RokomariBG_Dataset\"\n",
    "    USER_TO_REVIEW = DATA_FOLDER + r\"/user_to_review.json.gz\"\n",
    "    BOOK_TO_REVIEW = DATA_FOLDER + r\"/book_to_review.json.gz\"\n",
    "\n",
    "    K = 10\n",
    "\n",
    "    # -------------------------------\n",
    "    # Build user-book interactions\n",
    "    # -------------------------------\n",
    "    user_book = build_user_book_interactions(\n",
    "        USER_TO_REVIEW,\n",
    "        BOOK_TO_REVIEW,\n",
    "    )\n",
    "\n",
    "    print(f\"Total users with interactions: {len(user_book)}\")\n",
    "\n",
    "    evaluator = RankingEvaluator(k=K)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Split 70/15/15\n",
    "    # -------------------------------\n",
    "    train_user_book, val_user_book, test_user_book = split_user_interactions(\n",
    "        user_book\n",
    "    )\n",
    "\n",
    "    ground_truth = build_ground_truth(test_user_book)\n",
    "    test_users = list(ground_truth.keys())\n",
    "\n",
    "    print(f\"Users in test set: {len(test_users)}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # USER-BASED CF\n",
    "    # =====================================================\n",
    "\n",
    "    print(\"\\nTraining User-Based CF...\")\n",
    "\n",
    "    user_cf = UserBasedCFRecommender(\n",
    "        train_user_book=train_user_book,\n",
    "        k_neighbors=50,\n",
    "    )\n",
    "    user_cf.fit()\n",
    "\n",
    "    user_cf_preds = generate_predictions(user_cf, test_users, K)\n",
    "    user_cf_metrics = evaluator.evaluate(user_cf_preds, ground_truth)\n",
    "\n",
    "    print(\"\\n===== User-Based CF Results =====\")\n",
    "    for m, v in user_cf_metrics.items():\n",
    "        print(f\"{m}: {v:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b204dc91-b9b6-44b7-8ac8-f6f1234726e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
