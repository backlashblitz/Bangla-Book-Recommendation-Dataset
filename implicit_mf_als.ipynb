{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge implicit -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd9912-42b3-4cd6-8ffe-5a80b3011e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Set\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm.auto import tqdm\n",
    "from implicit.als import AlternatingLeastSquares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Utility Loader\n",
    "# ---------------------------------------\n",
    "\n",
    "def load_json(path: str):\n",
    "    with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "model",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitMFRecommender():\n",
    "    \"\"\"\n",
    "    Implicit Matrix Factorization using ALS (via implicit).\n",
    "    Train-only interactions. Guaranteed shape-safe.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_user_book: Dict[str, List[str]],\n",
    "        n_factors: int = 64,\n",
    "        n_iters: int = 20,\n",
    "        reg: float = 0.01,\n",
    "    ):\n",
    "        self.train_user_book = {u: list(set(b)) for u, b in train_user_book.items()}\n",
    "        self.n_factors = n_factors\n",
    "        self.n_iters = n_iters\n",
    "        self.reg = reg\n",
    "\n",
    "    def fit(self):\n",
    "        print(\"Training Implicit MF (ALS)...\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # Collect users and books\n",
    "        # -----------------------------\n",
    "        self.user_ids = sorted(self.train_user_book.keys())\n",
    "        \n",
    "        all_books = set()\n",
    "        for u, bl in self.train_user_book.items():\n",
    "            for b in bl:\n",
    "                all_books.add(b)\n",
    "                \n",
    "        self.book_ids = sorted(list(all_books))\n",
    "\n",
    "        self.user_id_map = {u: i for i, u in enumerate(self.user_ids)}\n",
    "        self.book_id_map = {b: i for i, b in enumerate(self.book_ids)}\n",
    "        self.reverse_book_id_map = {i: b for i, b in enumerate(self.book_ids)}\n",
    "\n",
    "        # -----------------------------\n",
    "        # Build USER–ITEM matrix\n",
    "        # -----------------------------\n",
    "        rows, cols = [], []\n",
    "        for u, books in self.train_user_book.items():\n",
    "            ui = self.user_id_map[u]\n",
    "            for b in books:\n",
    "                bi = self.book_id_map[b]\n",
    "                rows.append(ui)\n",
    "                cols.append(bi)\n",
    "\n",
    "        data = np.ones(len(rows), dtype=np.float32)\n",
    "\n",
    "        # USER–ITEM\n",
    "        self.user_item_matrix = csr_matrix(\n",
    "            (data, (rows, cols)),\n",
    "            shape=(len(self.user_ids), len(self.book_ids)),\n",
    "        )\n",
    "\n",
    "        # -----------------------------\n",
    "        # Train ALS\n",
    "        # -----------------------------\n",
    "        self.model = AlternatingLeastSquares(\n",
    "            factors=self.n_factors,\n",
    "            iterations=self.n_iters,\n",
    "            regularization=self.reg,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        self.model.fit(self.user_item_matrix)\n",
    "\n",
    "    def recommend(self, user_id: str, k: int = 10):\n",
    "        if user_id not in self.user_id_map:\n",
    "            return []\n",
    "\n",
    "        uidx = self.user_id_map[user_id]\n",
    "    \n",
    "        user_row = self.user_item_matrix[uidx]\n",
    "    \n",
    "        scores = self.model.recommend(\n",
    "            userid=uidx,\n",
    "            user_items=user_row,\n",
    "            N=k,\n",
    "            filter_already_liked_items=True,\n",
    "        )\n",
    "    \n",
    "        item_indices, _ = scores\n",
    "\n",
    "        recs = []\n",
    "        for i in item_indices:\n",
    "            recs.append(self.reverse_book_id_map[i])\n",
    "       \n",
    "        return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "evaluator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingEvaluator:\n",
    "    \"\"\"\n",
    "    Evaluation class for Top-N Recommendation.\n",
    "\n",
    "    Supports:\n",
    "        - Hit@K\n",
    "        - MRR@K\n",
    "        - NDCG@K\n",
    "\n",
    "    Input format:\n",
    "        predictions: Dict[user_id, List[item_id]]\n",
    "        ground_truth: Dict[user_id, Set[item_id]]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: int = 10):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Cutoff rank for evaluation (e.g., 5, 10, 20)\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "\n",
    "    # -------------------------\n",
    "    # Hit@K\n",
    "    # -------------------------\n",
    "    def hit_at_k(self, predictions: Dict, ground_truth: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Computes Hit@K\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float : Average Hit@K over users\n",
    "        \"\"\"\n",
    "        hits = []\n",
    "\n",
    "        for user in ground_truth:\n",
    "            if user not in predictions:\n",
    "                continue\n",
    "\n",
    "            top_k = predictions[user][:self.k]\n",
    "            gt_items = ground_truth[user]\n",
    "\n",
    "            hit = 1.0 if any(item in gt_items for item in top_k) else 0.0\n",
    "            hits.append(hit)\n",
    "\n",
    "        return float(np.mean(hits)) if hits else 0.0\n",
    "\n",
    "    # -------------------------\n",
    "    # MRR@K\n",
    "    # -------------------------\n",
    "    def mrr_at_k(self, predictions: Dict, ground_truth: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Computes Mean Reciprocal Rank (MRR@K)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float : Average MRR over users\n",
    "        \"\"\"\n",
    "        rr_scores = []\n",
    "\n",
    "        for user in ground_truth:\n",
    "            if user not in predictions:\n",
    "                continue\n",
    "\n",
    "            top_k = predictions[user][:self.k]\n",
    "            gt_items = ground_truth[user]\n",
    "\n",
    "            rr = 0.0\n",
    "            for rank, item in enumerate(top_k, start=1):\n",
    "                if item in gt_items:\n",
    "                    rr = 1.0 / rank\n",
    "                    break\n",
    "\n",
    "            rr_scores.append(rr)\n",
    "\n",
    "        return float(np.mean(rr_scores)) if rr_scores else 0.0\n",
    "\n",
    "    # -------------------------\n",
    "    # NDCG@K\n",
    "    # -------------------------\n",
    "    def ndcg_at_k(self, predictions: Dict, ground_truth: Dict) -> float:\n",
    "        \"\"\"\n",
    "        Computes Normalized Discounted Cumulative Gain (NDCG@K)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float : Average NDCG@K over users\n",
    "        \"\"\"\n",
    "        ndcg_scores = []\n",
    "\n",
    "        for user in tqdm(ground_truth, desc=\"Evaluating\"):\n",
    "            if user not in predictions:\n",
    "                continue\n",
    "\n",
    "            top_k = predictions[user][:self.k]\n",
    "            gt_items = ground_truth[user]\n",
    "\n",
    "            dcg = 0.0\n",
    "            for i, item in enumerate(top_k):\n",
    "                if item in gt_items:\n",
    "                    dcg += 1.0 / math.log2(i + 2)\n",
    "\n",
    "            ideal_hits = min(len(gt_items), self.k)\n",
    "            idcg = sum(1.0 / math.log2(i + 2) for i in range(ideal_hits))\n",
    "\n",
    "            ndcg = dcg / idcg if idcg > 0 else 0.0\n",
    "            ndcg_scores.append(ndcg)\n",
    "\n",
    "        return float(np.mean(ndcg_scores)) if ndcg_scores else 0.0\n",
    "\n",
    "    # -------------------------\n",
    "    # Combined Evaluation\n",
    "    # -------------------------\n",
    "    def evaluate(self, predictions: Dict, ground_truth: Dict) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Computes all metrics together.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dict[str, float]\n",
    "        \"\"\"\n",
    "        return {\n",
    "            f\"Hit@{self.k}\": self.hit_at_k(predictions, ground_truth),\n",
    "            f\"MRR@{self.k}\": self.mrr_at_k(predictions, ground_truth),\n",
    "            f\"NDCG@{self.k}\": self.ndcg_at_k(predictions, ground_truth),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_book_interactions(\n",
    "    user_to_review_path: str,\n",
    "    book_to_review_path: str,\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Builds:\n",
    "        user_id -> [book_id, book_id, ...]\n",
    "    \"\"\"\n",
    "    user_to_review = load_json(user_to_review_path)\n",
    "    book_to_review = load_json(book_to_review_path)\n",
    "\n",
    "    # Normalize IDs to string\n",
    "    review_to_user = {\n",
    "        str(x[\"review_id\"]): str(x[\"user_id\"])\n",
    "        for x in user_to_review\n",
    "    }\n",
    "\n",
    "    review_to_book = {\n",
    "        str(x[\"review_id\"]): str(x[\"book_id\"])\n",
    "        for x in book_to_review\n",
    "    }\n",
    "\n",
    "    user_book = defaultdict(list)\n",
    "\n",
    "    for rid, user_id in review_to_user.items():\n",
    "        if rid in review_to_book:\n",
    "            book_id = review_to_book[rid]\n",
    "            user_book[user_id].append(book_id)\n",
    "\n",
    "    return user_book\n",
    "\n",
    "\n",
    "def split_user_interactions(\n",
    "    user_book: Dict[str, List[str]],\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        train_user_book\n",
    "        val_user_book\n",
    "        test_user_book\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "\n",
    "    train = {}\n",
    "    val = {}\n",
    "    test = {}\n",
    "\n",
    "    for user, books in user_book.items():\n",
    "        books = list(set(books))  # remove duplicates\n",
    "        random.shuffle(books)\n",
    "\n",
    "        n = len(books)\n",
    "        if n < 3:\n",
    "            train[user] = books\n",
    "            val[user] = []\n",
    "            test[user] = []\n",
    "            continue\n",
    "\n",
    "        n_train = int(0.7 * n)\n",
    "        n_val = int(0.15 * n)\n",
    "\n",
    "        train[user] = books[:n_train]\n",
    "        val[user] = books[n_train : n_train + n_val]\n",
    "        test[user] = books[n_train + n_val :]\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def build_ground_truth(test_user_book: Dict[str, List[str]]) -> Dict[str, Set[str]]:\n",
    "    return {\n",
    "        user: set(books)\n",
    "        for user, books in test_user_book.items()\n",
    "        if len(books) > 0\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_predictions(model, users: List[str], k: int):\n",
    "    predictions = {}\n",
    "\n",
    "    for u in tqdm(users, desc=\"Generating Predictions\"):\n",
    "        preds = model.recommend(u, k)\n",
    "        predictions[u] = preds\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "main",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users with interactions: 63721\n",
      "Users in test set: 15427\n",
      "\n",
      "Training Implicit MF (ALS)...\n",
      "Training Implicit MF (ALS)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\python312\\Lib\\site-packages\\implicit\\cpu\\als.py:95: RuntimeWarning: Intel MKL BLAS is configured to use 8 threads. It is highly recommended to disable its internal threadpool by setting the environment variable 'MKL_NUM_THREADS=1' or by callng 'threadpoolctl.threadpool_limits(1, \"blas\")'. Having MKL use a threadpool can lead to severe performance issues\n",
      "  check_blas_config()\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  7.97it/s]\n",
      "Generating Predictions: 100%|██████████████████████████████████████████████████| 15427/15427 [00:07<00:00, 2147.19it/s]\n",
      "Evaluating: 100%|████████████████████████████████████████████████████████████| 15427/15427 [00:00<00:00, 213294.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Implicit MF Results =====\n",
      "Hit@10: 0.0839\n",
      "MRR@10: 0.0410\n",
      "NDCG@10: 0.0347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # -------------------------------\n",
    "    # Paths\n",
    "    # -------------------------------\n",
    "    DATA_FOLDER = r\"E:/RokomariBG_Dataset\"\n",
    "    USER_TO_REVIEW = DATA_FOLDER + r\"/user_to_review.json.gz\"\n",
    "    BOOK_TO_REVIEW = DATA_FOLDER + r\"/book_to_review.json.gz\"\n",
    "\n",
    "    K = 10\n",
    "\n",
    "    # -------------------------------\n",
    "    # Build user-book interactions\n",
    "    # -------------------------------\n",
    "    user_book = build_user_book_interactions(\n",
    "        USER_TO_REVIEW,\n",
    "        BOOK_TO_REVIEW,\n",
    "    )\n",
    "\n",
    "    print(f\"Total users with interactions: {len(user_book)}\")\n",
    "\n",
    "    evaluator = RankingEvaluator(k=K)\n",
    "\n",
    "    # -------------------------------\n",
    "    # Split 70/15/15\n",
    "    # -------------------------------\n",
    "    train_user_book, val_user_book, test_user_book = split_user_interactions(\n",
    "        user_book\n",
    "    )\n",
    "\n",
    "    ground_truth = build_ground_truth(test_user_book)\n",
    "    test_users = list(ground_truth.keys())\n",
    "\n",
    "    print(f\"Users in test set: {len(test_users)}\")\n",
    "\n",
    "    # =====================================================\n",
    "    # IMPLICIT MF (ALS)\n",
    "    # =====================================================\n",
    "\n",
    "    print(\"\\nTraining Implicit MF (ALS)...\")\n",
    "\n",
    "    implicit_mf = ImplicitMFRecommender(\n",
    "        train_user_book=train_user_book,\n",
    "        n_factors=64,\n",
    "        n_iters=20,\n",
    "    )\n",
    "\n",
    "    implicit_mf.fit()\n",
    "\n",
    "    implicit_preds = generate_predictions(implicit_mf, test_users, K)\n",
    "    implicit_metrics = evaluator.evaluate(implicit_preds, ground_truth)\n",
    "\n",
    "    print(\"\\n===== Implicit MF Results =====\")\n",
    "    for m, v in implicit_metrics.items():\n",
    "        print(f\"{m}: {v:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
