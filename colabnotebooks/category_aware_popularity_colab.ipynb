{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/backlashblitz/Bangla-Book-Recommendation-Dataset/blob/main/colabnotebooks/category_aware_popularity_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_3Tq8aTrLGa"
      },
      "source": [
        "# Category-Aware Popularity Recommender\n",
        "**Bangla Book Recommendation Dataset**\n",
        "\n",
        "This notebook automatically downloads the dataset from HuggingFace and runs the Category-Aware Popularity baseline recommender.\n",
        "\n",
        "â–¶ï¸ **Just click `Runtime â†’ Run all` to get started!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJOSnC_JrLGe"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# STEP 1: Install dependencies & download dataset from HuggingFace\n",
        "# ============================================================\n",
        "import os\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"ðŸ“¦ Installing huggingface_hub...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"huggingface_hub\"])\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "REPO_ID = \"DevnilMaster1/Bangla-Book-Recommendation-Dataset\"\n",
        "DATA_FOLDER = \"RokomariBG_Dataset\"\n",
        "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
        "\n",
        "# Files exist as plain .json on HuggingFace (not .gz)\n",
        "FILES_NEEDED = [\n",
        "    \"user_to_review.json\",\n",
        "    \"book_to_review.json\",\n",
        "    \"book_to_category.json\",\n",
        "]\n",
        "\n",
        "for filename in FILES_NEEDED:\n",
        "    dest = os.path.join(DATA_FOLDER, filename)\n",
        "    if os.path.exists(dest):\n",
        "        print(f\"âœ… Already downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"â¬‡ï¸  Downloading {filename} ...\")\n",
        "        downloaded_path = hf_hub_download(\n",
        "            repo_id=REPO_ID,\n",
        "            filename=filename,\n",
        "            repo_type=\"dataset\",\n",
        "        )\n",
        "        # Copy from HF cache to our data folder\n",
        "        import shutil\n",
        "        shutil.copy(downloaded_path, dest)\n",
        "        print(f\"âœ… Saved: {dest}\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ All files ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHVTRl5HrLGg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict, Counter\n",
        "from typing import Dict, List, Set\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zn9lSAhZrLGh"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------\n",
        "# Utility Loader\n",
        "# Note: HuggingFace files are plain .json (not .gz)\n",
        "# ---------------------------------------\n",
        "\n",
        "def load_json(path: str):\n",
        "    \"\"\"Load JSON file â€” supports both plain .json and gzip .json.gz\"\"\"\n",
        "    if path.endswith(\".gz\"):\n",
        "        import gzip\n",
        "        with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    else:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzAT2KuPrLGh"
      },
      "outputs": [],
      "source": [
        "class CategoryAwarePopularityRecommender():\n",
        "    \"\"\"\n",
        "    Recommends popular books within user's preferred categories.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        user_to_review_path: str,\n",
        "        book_to_review_path: str,\n",
        "        book_to_category_path: str,\n",
        "    ):\n",
        "        self.user_to_review_path = user_to_review_path\n",
        "        self.book_to_review_path = book_to_review_path\n",
        "        self.book_to_category_path = book_to_category_path\n",
        "\n",
        "        self.user_category_pref = defaultdict(Counter)\n",
        "        self.category_book_popularity = defaultdict(list)\n",
        "\n",
        "    def fit(self):\n",
        "        user_to_review = load_json(self.user_to_review_path)\n",
        "        book_to_review = load_json(self.book_to_review_path)\n",
        "        book_to_category = load_json(self.book_to_category_path)\n",
        "\n",
        "        review_to_user = {\n",
        "            str(x[\"review_id\"]): str(x[\"user_id\"])\n",
        "            for x in user_to_review\n",
        "        }\n",
        "\n",
        "        review_to_book = {\n",
        "            str(x[\"review_id\"]): str(x[\"book_id\"])\n",
        "            for x in book_to_review\n",
        "        }\n",
        "\n",
        "        book_to_categories = defaultdict(set)\n",
        "        for x in book_to_category:\n",
        "            book_id = str(x[\"book_id\"])\n",
        "            category_id = str(x[\"category_id\"])\n",
        "            book_to_categories[book_id].add(category_id)\n",
        "\n",
        "        for rid, user_id in review_to_user.items():\n",
        "            if rid in review_to_book:\n",
        "                book_id = review_to_book[rid]\n",
        "                categories = book_to_categories.get(book_id, [])\n",
        "                for c in categories:\n",
        "                    self.user_category_pref[user_id][c] += 1\n",
        "\n",
        "        category_counters = defaultdict(Counter)\n",
        "        for x in book_to_review:\n",
        "            rid = str(x[\"review_id\"])\n",
        "            book_id = str(x[\"book_id\"])\n",
        "            categories = book_to_categories.get(book_id, [])\n",
        "            for c in categories:\n",
        "                category_counters[c][book_id] += 1\n",
        "\n",
        "        for cat, counter in category_counters.items():\n",
        "            self.category_book_popularity[cat] = [\n",
        "                book_id for book_id, _ in counter.most_common()\n",
        "            ]\n",
        "\n",
        "    def recommend(self, user_id: str, k: int = 10) -> List[str]:\n",
        "        user_id = str(user_id)\n",
        "\n",
        "        if user_id not in self.user_category_pref:\n",
        "            if not self.category_book_popularity:\n",
        "                return []\n",
        "            random_cat = random.choice(list(self.category_book_popularity.keys()))\n",
        "            return self.category_book_popularity[random_cat][:k]\n",
        "\n",
        "        preferred_categories = [\n",
        "            c for c, _ in self.user_category_pref[user_id].most_common()\n",
        "        ]\n",
        "\n",
        "        recommendations = []\n",
        "        seen_books = set()\n",
        "\n",
        "        for cat in preferred_categories:\n",
        "            for book_id in self.category_book_popularity.get(cat, []):\n",
        "                if book_id not in seen_books:\n",
        "                    recommendations.append(book_id)\n",
        "                    seen_books.add(book_id)\n",
        "                if len(recommendations) >= k:\n",
        "                    return recommendations\n",
        "\n",
        "        return recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHd-9_ODrLGh"
      },
      "outputs": [],
      "source": [
        "class RankingEvaluator:\n",
        "    \"\"\"\n",
        "    Evaluates ranking-based recommendation metrics.\n",
        "    Computes: Hit@K, MRR@K, NDCG@K for various K values.\n",
        "    \"\"\"\n",
        "\n",
        "    def hit_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        return 1.0 if any(item in ground_truth for item in predictions[:k]) else 0.0\n",
        "\n",
        "    def mrr_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        for rank, item in enumerate(predictions[:k], start=1):\n",
        "            if item in ground_truth:\n",
        "                return 1.0 / rank\n",
        "        return 0.0\n",
        "\n",
        "    def dcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        return sum(\n",
        "            1.0 / np.log2(rank + 1)\n",
        "            for rank, item in enumerate(predictions[:k], start=1)\n",
        "            if item in ground_truth\n",
        "        )\n",
        "\n",
        "    def idcg_at_k(self, ground_truth: Set[str], k: int) -> float:\n",
        "        ideal_k = min(len(ground_truth), k)\n",
        "        return sum(1.0 / np.log2(rank + 1) for rank in range(1, ideal_k + 1))\n",
        "\n",
        "    def ndcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        idcg = self.idcg_at_k(ground_truth, k)\n",
        "        return self.dcg_at_k(predictions, ground_truth, k) / idcg if idcg > 0 else 0.0\n",
        "\n",
        "    def evaluate(self, predictions: Dict[str, List[str]], ground_truth: Dict[str, Set[str]]) -> Dict[str, float]:\n",
        "        metrics = {'Hit@5': [], 'Hit@10': [], 'Hit@50': [], 'MRR@10': [], 'NDCG@10': [], 'NDCG@50': []}\n",
        "        common_users = set(predictions.keys()) & set(ground_truth.keys())\n",
        "\n",
        "        for user_id in common_users:\n",
        "            preds = predictions[user_id]\n",
        "            gt = ground_truth[user_id]\n",
        "            if len(gt) == 0:\n",
        "                continue\n",
        "            metrics['Hit@5'].append(self.hit_at_k(preds, gt, 5))\n",
        "            metrics['Hit@10'].append(self.hit_at_k(preds, gt, 10))\n",
        "            metrics['Hit@50'].append(self.hit_at_k(preds, gt, 50))\n",
        "            metrics['MRR@10'].append(self.mrr_at_k(preds, gt, 10))\n",
        "            metrics['NDCG@10'].append(self.ndcg_at_k(preds, gt, 10))\n",
        "            metrics['NDCG@50'].append(self.ndcg_at_k(preds, gt, 50))\n",
        "\n",
        "        return {k: np.mean(v) if v else 0.0 for k, v in metrics.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jgd87mMxrLGi"
      },
      "outputs": [],
      "source": [
        "def build_user_book_interactions(user_to_review_path, book_to_review_path):\n",
        "    user_to_review = load_json(user_to_review_path)\n",
        "    book_to_review = load_json(book_to_review_path)\n",
        "\n",
        "    review_to_user = {str(x[\"review_id\"]): str(x[\"user_id\"]) for x in user_to_review}\n",
        "    review_to_book = {str(x[\"review_id\"]): str(x[\"book_id\"]) for x in book_to_review}\n",
        "\n",
        "    user_book = defaultdict(list)\n",
        "    for rid, user_id in review_to_user.items():\n",
        "        if rid in review_to_book:\n",
        "            user_book[user_id].append(review_to_book[rid])\n",
        "\n",
        "    return user_book\n",
        "\n",
        "\n",
        "def split_user_interactions(user_book, seed=42):\n",
        "    random.seed(seed)\n",
        "    train, val, test = {}, {}, {}\n",
        "\n",
        "    for user, books in user_book.items():\n",
        "        books = list(set(books))\n",
        "        random.shuffle(books)\n",
        "        n = len(books)\n",
        "\n",
        "        if n < 3:\n",
        "            train[user], val[user], test[user] = books, [], []\n",
        "            continue\n",
        "\n",
        "        n_train = int(0.7 * n)\n",
        "        n_val = int(0.15 * n)\n",
        "        train[user] = books[:n_train]\n",
        "        val[user] = books[n_train: n_train + n_val]\n",
        "        test[user] = books[n_train + n_val:]\n",
        "\n",
        "    return train, val, test\n",
        "\n",
        "\n",
        "def build_ground_truth(test_user_book):\n",
        "    return {user: set(books) for user, books in test_user_book.items() if books}\n",
        "\n",
        "\n",
        "def generate_predictions(model, users, k):\n",
        "    predictions = {}\n",
        "    for u in tqdm(users, desc=\"Generating Predictions\"):\n",
        "        predictions[u] = model.recommend(u, k)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvAp6BTGrLGi"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # -------------------------------\n",
        "    # Paths  (plain .json from HuggingFace)\n",
        "    # -------------------------------\n",
        "    DATA_FOLDER = \"RokomariBG_Dataset/\"\n",
        "    USER_TO_REVIEW   = DATA_FOLDER + \"user_to_review.json\"\n",
        "    BOOK_TO_REVIEW   = DATA_FOLDER + \"book_to_review.json\"\n",
        "    BOOK_TO_CATEGORY = DATA_FOLDER + \"book_to_category.json\"\n",
        "\n",
        "    K = 10\n",
        "\n",
        "    # Build user-book interactions\n",
        "    user_book = build_user_book_interactions(USER_TO_REVIEW, BOOK_TO_REVIEW)\n",
        "    print(f\"Total users with interactions: {len(user_book)}\")\n",
        "\n",
        "    evaluator = RankingEvaluator()\n",
        "\n",
        "    # Split 70/15/15\n",
        "    train_user_book, val_user_book, test_user_book = split_user_interactions(user_book)\n",
        "    ground_truth = build_ground_truth(test_user_book)\n",
        "    test_users = list(ground_truth.keys())\n",
        "    print(f\"Users in test set: {len(test_users)}\")\n",
        "\n",
        "    # =====================================================\n",
        "    # CATEGORY-AWARE POPULARITY BASELINE\n",
        "    # =====================================================\n",
        "    print(\"\\nTraining Category-Aware Popularity Baseline...\")\n",
        "\n",
        "    cat_model = CategoryAwarePopularityRecommender(\n",
        "        user_to_review_path=USER_TO_REVIEW,\n",
        "        book_to_review_path=BOOK_TO_REVIEW,\n",
        "        book_to_category_path=BOOK_TO_CATEGORY,\n",
        "    )\n",
        "    cat_model.fit()\n",
        "\n",
        "    cat_predictions = generate_predictions(cat_model, test_users, K)\n",
        "    cat_metrics = evaluator.evaluate(cat_predictions, ground_truth)\n",
        "\n",
        "    print(\"\\n===== Category-Aware Popularity Results =====\")\n",
        "    for m, v in cat_metrics.items():\n",
        "        print(f\"{m}: {v:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}