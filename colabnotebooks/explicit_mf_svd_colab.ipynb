{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "x1651245",
      "metadata": {
        "id": "x1651245"
      },
      "source": [
        "# Explicit Matrix Factorization (SVD)\n",
        "**Bangla Book Recommendation Dataset**\n",
        "\n",
        "‚ñ∂Ô∏è **Just click `Runtime ‚Üí Run all` to get started!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "67195675",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67195675",
        "outputId": "c8ba7bd4-dd5b-4975-a724-c1306853109b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Installing required packages...\n",
            "\n",
            "‚ö†Ô∏è  NumPy was downgraded. Restarting kernel to apply changes...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 1: Install dependencies & download dataset from HuggingFace\n",
        "# ============================================================\n",
        "import os, shutil\n",
        "\n",
        "print(\"üì¶ Installing required packages...\")\n",
        "# scikit-surprise requires NumPy < 2.0 ‚Äî must downgrade first\n",
        "os.system(\"pip install -q 'numpy<2' scikit-surprise huggingface_hub tqdm pandas\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  NumPy was downgraded. Restarting kernel to apply changes...\")\n",
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(restart=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "19018914",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19018914",
        "outputId": "075a6924-9ff9-4c15-d5de-3f4e3657f472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Already downloaded: user_to_review.json\n",
            "‚úÖ Already downloaded: book_to_review.json\n",
            "‚úÖ Already downloaded: review.json\n",
            "\n",
            "üéâ All files ready!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# STEP 2: Download dataset from HuggingFace\n",
        "# (Run this cell after the kernel restarts from Step 1)\n",
        "# ============================================================\n",
        "import os, shutil\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "REPO_ID = \"DevnilMaster1/Bangla-Book-Recommendation-Dataset\"\n",
        "DATA_FOLDER = \"RokomariBG_Dataset\"\n",
        "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
        "\n",
        "FILES_NEEDED = [\"user_to_review.json\", \"book_to_review.json\", \"review.json\"]\n",
        "\n",
        "for filename in FILES_NEEDED:\n",
        "    dest = os.path.join(DATA_FOLDER, filename)\n",
        "    if os.path.exists(dest):\n",
        "        print(f\"‚úÖ Already downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"‚¨áÔ∏è  Downloading {filename} ...\")\n",
        "        downloaded_path = hf_hub_download(\n",
        "            repo_id=REPO_ID,\n",
        "            filename=filename,\n",
        "            repo_type=\"dataset\",\n",
        "        )\n",
        "        shutil.copy(downloaded_path, dest)\n",
        "        print(f\"‚úÖ Saved: {dest}\")\n",
        "\n",
        "print(\"\\nüéâ All files ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "x5173347",
      "metadata": {
        "id": "x5173347"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Set\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from surprise import Dataset, Reader, SVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "60415825",
      "metadata": {
        "id": "60415825"
      },
      "outputs": [],
      "source": [
        "def load_json(path: str):\n",
        "    \"\"\"Load JSON file ‚Äî supports both plain .json and gzip .json.gz\"\"\"\n",
        "    import json\n",
        "    if path.endswith(\".gz\"):\n",
        "        import gzip\n",
        "        with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    else:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "86551798",
      "metadata": {
        "id": "86551798"
      },
      "outputs": [],
      "source": [
        "class ExplicitMFRecommender():\n",
        "    \"\"\"Explicit Matrix Factorization using SVD (via Surprise). Train-only ratings.\"\"\"\n",
        "\n",
        "    def __init__(self, train_user_book_rating: Dict[str, Dict[str, float]]):\n",
        "        self.train_data = train_user_book_rating\n",
        "\n",
        "    def fit(self):\n",
        "        print(\"Training Explicit MF (SVD)...\")\n",
        "        records = []\n",
        "        for user, book_dict in self.train_data.items():\n",
        "            for book, rating in book_dict.items():\n",
        "                records.append([user, book, float(rating)])\n",
        "\n",
        "        reader = Reader(rating_scale=(1, 5))\n",
        "        self.data = Dataset.load_from_df(\n",
        "            pd.DataFrame(records, columns=[\"user\", \"item\", \"rating\"]), reader)\n",
        "        trainset = self.data.build_full_trainset()\n",
        "        self.model = SVD(random_state=42)\n",
        "        self.model.fit(trainset)\n",
        "        self.all_items = set(b for u in self.train_data for b in self.train_data[u])\n",
        "\n",
        "    def recommend(self, user_id: str, k: int = 10, n_candidates: int = 1000):\n",
        "        if user_id not in self.train_data:\n",
        "            return []\n",
        "        seen = set(self.train_data[user_id].keys())\n",
        "        unseen_items = list(self.all_items - seen)\n",
        "        candidates = random.sample(unseen_items, n_candidates) if len(unseen_items) > n_candidates else unseen_items\n",
        "        scores = [(book, self.model.predict(user_id, book).est) for book in candidates]\n",
        "        scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        return [b for b, _ in scores[:k]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "x4688123",
      "metadata": {
        "id": "x4688123"
      },
      "outputs": [],
      "source": [
        "class RankingEvaluator:\n",
        "    def hit_at_k(self, predictions, ground_truth, k):\n",
        "        return 1.0 if any(item in ground_truth for item in predictions[:k]) else 0.0\n",
        "\n",
        "    def mrr_at_k(self, predictions, ground_truth, k):\n",
        "        for rank, item in enumerate(predictions[:k], start=1):\n",
        "            if item in ground_truth:\n",
        "                return 1.0 / rank\n",
        "        return 0.0\n",
        "\n",
        "    def dcg_at_k(self, predictions, ground_truth, k):\n",
        "        return sum(1.0 / np.log2(r+1) for r, item in enumerate(predictions[:k], 1) if item in ground_truth)\n",
        "\n",
        "    def idcg_at_k(self, ground_truth, k):\n",
        "        return sum(1.0 / np.log2(r+1) for r in range(1, min(len(ground_truth), k)+1))\n",
        "\n",
        "    def ndcg_at_k(self, predictions, ground_truth, k):\n",
        "        idcg = self.idcg_at_k(ground_truth, k)\n",
        "        return self.dcg_at_k(predictions, ground_truth, k) / idcg if idcg > 0 else 0.0\n",
        "\n",
        "    def evaluate(self, predictions, ground_truth):\n",
        "        metrics = {k: [] for k in ['Hit@5','Hit@10','Hit@50','MRR@10','NDCG@10','NDCG@50']}\n",
        "        for uid in set(predictions) & set(ground_truth):\n",
        "            p, g = predictions[uid], ground_truth[uid]\n",
        "            if not g: continue\n",
        "            metrics['Hit@5'].append(self.hit_at_k(p, g, 5))\n",
        "            metrics['Hit@10'].append(self.hit_at_k(p, g, 10))\n",
        "            metrics['Hit@50'].append(self.hit_at_k(p, g, 50))\n",
        "            metrics['MRR@10'].append(self.mrr_at_k(p, g, 10))\n",
        "            metrics['NDCG@10'].append(self.ndcg_at_k(p, g, 10))\n",
        "            metrics['NDCG@50'].append(self.ndcg_at_k(p, g, 50))\n",
        "        return {k: np.mean(v) if v else 0.0 for k, v in metrics.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "x6948070",
      "metadata": {
        "id": "x6948070"
      },
      "outputs": [],
      "source": [
        "def build_user_book_interactions(user_to_review_path, book_to_review_path):\n",
        "    user_to_review = load_json(user_to_review_path)\n",
        "    book_to_review = load_json(book_to_review_path)\n",
        "    review_to_user = {str(x[\"review_id\"]): str(x[\"user_id\"]) for x in user_to_review}\n",
        "    review_to_book = {str(x[\"review_id\"]): str(x[\"book_id\"]) for x in book_to_review}\n",
        "    user_book = defaultdict(list)\n",
        "    for rid, uid in review_to_user.items():\n",
        "        if rid in review_to_book:\n",
        "            user_book[uid].append(review_to_book[rid])\n",
        "    return user_book\n",
        "\n",
        "def split_user_interactions(user_book, seed=42):\n",
        "    random.seed(seed)\n",
        "    train, val, test = {}, {}, {}\n",
        "    for user, books in user_book.items():\n",
        "        books = list(set(books)); random.shuffle(books); n = len(books)\n",
        "        if n < 3:\n",
        "            train[user], val[user], test[user] = books, [], []\n",
        "        else:\n",
        "            nt, nv = int(0.7*n), int(0.15*n)\n",
        "            train[user], val[user], test[user] = books[:nt], books[nt:nt+nv], books[nt+nv:]\n",
        "    return train, val, test\n",
        "\n",
        "def build_ground_truth(test_user_book):\n",
        "    return {u: set(b) for u, b in test_user_book.items() if b}\n",
        "\n",
        "def generate_predictions(model, users, k):\n",
        "    predictions = {}\n",
        "    for u in tqdm(users, desc=\"Generating Predictions\"):\n",
        "        predictions[u] = model.recommend(u, k)\n",
        "    return predictions\n",
        "\n",
        "def build_train_user_book_rating(train_user_book, user_to_review_path, book_to_review_path, review_path):\n",
        "    user_to_review = load_json(user_to_review_path)\n",
        "    book_to_review = load_json(book_to_review_path)\n",
        "    reviews = load_json(review_path)\n",
        "    review_to_user = {str(x[\"review_id\"]): str(x[\"user_id\"]) for x in user_to_review}\n",
        "    review_to_book = {str(x[\"review_id\"]): str(x[\"book_id\"]) for x in book_to_review}\n",
        "    # Support both \"user_rating\" and \"userRating\" key names\n",
        "    def get_rating(x):\n",
        "        return float(x.get(\"user_rating\", x.get(\"userRating\", 0)))\n",
        "    review_to_rating = {str(x[\"review_id\"]): get_rating(x) for x in reviews}\n",
        "    train_ratings = defaultdict(dict)\n",
        "    for rid, user in review_to_user.items():\n",
        "        if rid in review_to_book and rid in review_to_rating:\n",
        "            book = review_to_book[rid]\n",
        "            rating = review_to_rating[rid]\n",
        "            if rating > 0 and user in train_user_book and book in train_user_book[user]:\n",
        "                train_ratings[user][book] = rating\n",
        "    return train_ratings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    DATA_FOLDER = \"RokomariBG_Dataset/\"\n",
        "    USER_TO_REVIEW = DATA_FOLDER + \"user_to_review.json\"\n",
        "    BOOK_TO_REVIEW = DATA_FOLDER + \"book_to_review.json\"\n",
        "    REVIEW         = DATA_FOLDER + \"review.json\"\n",
        "    K = 10\n",
        "\n",
        "    user_book = build_user_book_interactions(USER_TO_REVIEW, BOOK_TO_REVIEW)\n",
        "    print(f\"Total users with interactions: {len(user_book)}\")\n",
        "\n",
        "    evaluator = RankingEvaluator()\n",
        "    train_user_book, val_user_book, test_user_book = split_user_interactions(user_book)\n",
        "    ground_truth = build_ground_truth(test_user_book)\n",
        "    test_users = list(ground_truth.keys())\n",
        "    print(f\"Users in test set: {len(test_users)}\")\n",
        "\n",
        "    print(\"\\nBuilding rating matrix from training data...\")\n",
        "    train_user_book_rating = build_train_user_book_rating(\n",
        "        train_user_book=train_user_book,\n",
        "        user_to_review_path=USER_TO_REVIEW,\n",
        "        book_to_review_path=BOOK_TO_REVIEW,\n",
        "        review_path=REVIEW,\n",
        "    )\n",
        "\n",
        "    print(\"\\nTraining Explicit MF (SVD)...\")\n",
        "    explicit_mf = ExplicitMFRecommender(train_user_book_rating)\n",
        "    explicit_mf.fit()\n",
        "\n",
        "    explicit_preds = generate_predictions(explicit_mf, test_users, K)\n",
        "    explicit_metrics = evaluator.evaluate(explicit_preds, ground_truth)\n",
        "\n",
        "    print(\"\\n===== Explicit MF Results =====\")\n",
        "    for m, v in explicit_metrics.items():\n",
        "        print(f\"{m}: {v:.4f}\")\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weds03VZy3Vl",
        "outputId": "d5667dea-701b-4a7c-9d52-2fa86b83ddc6"
      },
      "id": "weds03VZy3Vl",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total users with interactions: 63721\n",
            "Users in test set: 15427\n",
            "\n",
            "Building rating matrix from training data...\n",
            "\n",
            "Training Explicit MF (SVD)...\n",
            "Training Explicit MF (SVD)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating Predictions: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15427/15427 [01:58<00:00, 130.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Explicit MF Results =====\n",
            "Hit@5: 0.0029\n",
            "Hit@10: 0.0052\n",
            "Hit@50: 0.0052\n",
            "MRR@10: 0.0017\n",
            "NDCG@10: 0.0016\n",
            "NDCG@50: 0.0016\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}