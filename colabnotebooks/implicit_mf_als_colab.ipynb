{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/backlashblitz/Bangla-Book-Recommendation-Dataset/blob/main/colabnotebooks/implicit_mf_als_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55765622"
      },
      "source": [
        "# Implicit Matrix Factorization (ALS)\n",
        "**Bangla Book Recommendation Dataset**\n",
        "\n",
        "â–¶ï¸ **Just click `Runtime â†’ Run all` to get started!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75253194"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Install dependencies\n",
        "# ============================================================\n",
        "import os\n",
        "os.system(\"pip install -q huggingface_hub tqdm implicit scipy\")\n",
        "print(\"âœ… Packages installed!\")\n",
        "\n",
        "# ============================================================\n",
        "# Download dataset from HuggingFace\n",
        "# ============================================================\n",
        "import os, shutil\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "REPO_ID = \"DevnilMaster1/Bangla-Book-Recommendation-Dataset\"\n",
        "DATA_FOLDER = \"RokomariBG_Dataset\"\n",
        "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
        "\n",
        "FILES_NEEDED = ['user_to_review.json', 'book_to_review.json']\n",
        "\n",
        "for filename in FILES_NEEDED:\n",
        "    dest = os.path.join(DATA_FOLDER, filename)\n",
        "    if os.path.exists(dest):\n",
        "        print(f\"âœ… Already downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"â¬‡ï¸  Downloading {filename} ...\")\n",
        "        downloaded_path = hf_hub_download(\n",
        "            repo_id=REPO_ID,\n",
        "            filename=filename,\n",
        "            repo_type=\"dataset\",\n",
        "        )\n",
        "        shutil.copy(downloaded_path, dest)\n",
        "        print(f\"âœ… Saved: {dest}\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ All files ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31460700"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import gzip\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Set\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.sparse import csr_matrix\n",
        "from tqdm.auto import tqdm\n",
        "from implicit.als import AlternatingLeastSquares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13058935"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------\n",
        "# Utility Loader\n",
        "# ---------------------------------------\n",
        "\n",
        "def load_json(path: str):\n",
        "    \"\"\"Supports both plain .json and gzip .json\"\"\"\n",
        "    if path.endswith(\".gz\"):\n",
        "        import gzip\n",
        "        with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    else:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61802243"
      },
      "outputs": [],
      "source": [
        "class ImplicitMFRecommender():\n",
        "    \"\"\"\n",
        "    Implicit Matrix Factorization using ALS (via implicit).\n",
        "    Train-only interactions. Guaranteed shape-safe.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_user_book: Dict[str, List[str]],\n",
        "        n_factors: int = 64,\n",
        "        n_iters: int = 20,\n",
        "        reg: float = 0.01,\n",
        "    ):\n",
        "        self.train_user_book = {u: list(set(b)) for u, b in train_user_book.items()}\n",
        "        self.n_factors = n_factors\n",
        "        self.n_iters = n_iters\n",
        "        self.reg = reg\n",
        "\n",
        "    def fit(self):\n",
        "        print(\"Training Implicit MF (ALS)...\")\n",
        "\n",
        "        # -----------------------------\n",
        "        # Collect users and books\n",
        "        # -----------------------------\n",
        "        self.user_ids = sorted(self.train_user_book.keys())\n",
        "\n",
        "        all_books = set()\n",
        "        for u, bl in self.train_user_book.items():\n",
        "            for b in bl:\n",
        "                all_books.add(b)\n",
        "\n",
        "        self.book_ids = sorted(list(all_books))\n",
        "\n",
        "        self.user_id_map = {u: i for i, u in enumerate(self.user_ids)}\n",
        "        self.book_id_map = {b: i for i, b in enumerate(self.book_ids)}\n",
        "        self.reverse_book_id_map = {i: b for i, b in enumerate(self.book_ids)}\n",
        "\n",
        "        # -----------------------------\n",
        "        # Build USERâ€“ITEM matrix\n",
        "        # -----------------------------\n",
        "        rows, cols = [], []\n",
        "        for u, books in self.train_user_book.items():\n",
        "            ui = self.user_id_map[u]\n",
        "            for b in books:\n",
        "                bi = self.book_id_map[b]\n",
        "                rows.append(ui)\n",
        "                cols.append(bi)\n",
        "\n",
        "        data = np.ones(len(rows), dtype=np.float32)\n",
        "\n",
        "        # USERâ€“ITEM\n",
        "        self.user_item_matrix = csr_matrix(\n",
        "            (data, (rows, cols)),\n",
        "            shape=(len(self.user_ids), len(self.book_ids)),\n",
        "        )\n",
        "\n",
        "        # -----------------------------\n",
        "        # Train ALS\n",
        "        # -----------------------------\n",
        "        self.model = AlternatingLeastSquares(\n",
        "            factors=self.n_factors,\n",
        "            iterations=self.n_iters,\n",
        "            regularization=self.reg,\n",
        "            random_state=42,\n",
        "        )\n",
        "\n",
        "        self.model.fit(self.user_item_matrix)\n",
        "\n",
        "    def recommend(self, user_id: str, k: int = 10):\n",
        "        if user_id not in self.user_id_map:\n",
        "            return []\n",
        "\n",
        "        uidx = self.user_id_map[user_id]\n",
        "\n",
        "        user_row = self.user_item_matrix[uidx]\n",
        "\n",
        "        scores = self.model.recommend(\n",
        "            userid=uidx,\n",
        "            user_items=user_row,\n",
        "            N=k,\n",
        "            filter_already_liked_items=True,\n",
        "        )\n",
        "\n",
        "        item_indices, _ = scores\n",
        "\n",
        "        recs = []\n",
        "        for i in item_indices:\n",
        "            recs.append(self.reverse_book_id_map[i])\n",
        "\n",
        "        return recs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43411754"
      },
      "outputs": [],
      "source": [
        "class RankingEvaluator:\n",
        "    \"\"\"\n",
        "    Evaluates ranking-based recommendation metrics.\n",
        "    Computes: Hit@K, MRR@K, NDCG@K for various K values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def hit_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        Hit@K: 1 if at least one relevant item is in top-K, else 0\n",
        "        \"\"\"\n",
        "        top_k = predictions[:k]\n",
        "        return 1.0 if any(item in ground_truth for item in top_k) else 0.0\n",
        "\n",
        "    def mrr_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        MRR@K: Reciprocal rank of first relevant item in top-K\n",
        "        \"\"\"\n",
        "        top_k = predictions[:k]\n",
        "        for rank, item in enumerate(top_k, start=1):\n",
        "            if item in ground_truth:\n",
        "                return 1.0 / rank\n",
        "        return 0.0\n",
        "\n",
        "    def dcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        DCG@K: Discounted Cumulative Gain\n",
        "        \"\"\"\n",
        "        dcg = 0.0\n",
        "        top_k = predictions[:k]\n",
        "        for rank, item in enumerate(top_k, start=1):\n",
        "            if item in ground_truth:\n",
        "                dcg += 1.0 / np.log2(rank + 1)\n",
        "        return dcg\n",
        "\n",
        "    def idcg_at_k(self, ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        IDCG@K: Ideal DCG (best possible DCG)\n",
        "        \"\"\"\n",
        "        ideal_k = min(len(ground_truth), k)\n",
        "        idcg = sum(1.0 / np.log2(rank + 1) for rank in range(1, ideal_k + 1))\n",
        "        return idcg\n",
        "\n",
        "    def ndcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        NDCG@K: Normalized Discounted Cumulative Gain\n",
        "        \"\"\"\n",
        "        dcg = self.dcg_at_k(predictions, ground_truth, k)\n",
        "        idcg = self.idcg_at_k(ground_truth, k)\n",
        "\n",
        "        if idcg == 0.0:\n",
        "            return 0.0\n",
        "\n",
        "        return dcg / idcg\n",
        "\n",
        "    def evaluate(self, predictions: Dict[str, List[str]], ground_truth: Dict[str, Set[str]]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate predictions against ground truth.\n",
        "\n",
        "        Args:\n",
        "            predictions: Dict mapping user_id -> list of recommended item_ids (ranked)\n",
        "            ground_truth: Dict mapping user_id -> set of relevant item_ids\n",
        "\n",
        "        Returns:\n",
        "            Dict of metric_name -> average_score\n",
        "        \"\"\"\n",
        "        metrics = {\n",
        "            'Hit@5': [],\n",
        "            'Hit@10': [],\n",
        "            'Hit@50': [],\n",
        "            'MRR@10': [],\n",
        "            'NDCG@10': [],\n",
        "            'NDCG@50': []\n",
        "        }\n",
        "\n",
        "        # Only evaluate users present in both predictions and ground_truth\n",
        "        common_users = set(predictions.keys()) & set(ground_truth.keys())\n",
        "\n",
        "        for user_id in common_users:\n",
        "            preds = predictions[user_id]\n",
        "            gt = ground_truth[user_id]\n",
        "\n",
        "            # Skip users with no ground truth items\n",
        "            if len(gt) == 0:\n",
        "                continue\n",
        "\n",
        "            # Compute metrics\n",
        "            metrics['Hit@5'].append(self.hit_at_k(preds, gt, 5))\n",
        "            metrics['Hit@10'].append(self.hit_at_k(preds, gt, 10))\n",
        "            metrics['Hit@50'].append(self.hit_at_k(preds, gt, 50))\n",
        "            metrics['MRR@10'].append(self.mrr_at_k(preds, gt, 10))\n",
        "            metrics['NDCG@10'].append(self.ndcg_at_k(preds, gt, 10))\n",
        "            metrics['NDCG@50'].append(self.ndcg_at_k(preds, gt, 50))\n",
        "\n",
        "        # Average across all users\n",
        "        results = {}\n",
        "        for metric_name, values in metrics.items():\n",
        "            if len(values) > 0:\n",
        "                results[metric_name] = np.mean(values)\n",
        "            else:\n",
        "                results[metric_name] = 0.0\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89126848"
      },
      "outputs": [],
      "source": [
        "def build_user_book_interactions(\n",
        "    user_to_review_path: str,\n",
        "    book_to_review_path: str,\n",
        ") -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Builds:\n",
        "        user_id -> [book_id, book_id, ...]\n",
        "    \"\"\"\n",
        "    user_to_review = load_json(user_to_review_path)\n",
        "    book_to_review = load_json(book_to_review_path)\n",
        "\n",
        "    # Normalize IDs to string\n",
        "    review_to_user = {\n",
        "        str(x[\"review_id\"]): str(x[\"user_id\"])\n",
        "        for x in user_to_review\n",
        "    }\n",
        "\n",
        "    review_to_book = {\n",
        "        str(x[\"review_id\"]): str(x[\"book_id\"])\n",
        "        for x in book_to_review\n",
        "    }\n",
        "\n",
        "    user_book = defaultdict(list)\n",
        "\n",
        "    for rid, user_id in review_to_user.items():\n",
        "        if rid in review_to_book:\n",
        "            book_id = review_to_book[rid]\n",
        "            user_book[user_id].append(book_id)\n",
        "\n",
        "    return user_book\n",
        "\n",
        "\n",
        "def split_user_interactions(\n",
        "    user_book: Dict[str, List[str]],\n",
        "    seed: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        train_user_book\n",
        "        val_user_book\n",
        "        test_user_book\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "\n",
        "    train = {}\n",
        "    val = {}\n",
        "    test = {}\n",
        "\n",
        "    for user, books in user_book.items():\n",
        "        books = list(set(books))  # remove duplicates\n",
        "        random.shuffle(books)\n",
        "\n",
        "        n = len(books)\n",
        "        if n < 3:\n",
        "            train[user] = books\n",
        "            val[user] = []\n",
        "            test[user] = []\n",
        "            continue\n",
        "\n",
        "        n_train = int(0.7 * n)\n",
        "        n_val = int(0.15 * n)\n",
        "\n",
        "        train[user] = books[:n_train]\n",
        "        val[user] = books[n_train : n_train + n_val]\n",
        "        test[user] = books[n_train + n_val :]\n",
        "\n",
        "    return train, val, test\n",
        "\n",
        "\n",
        "def build_ground_truth(test_user_book: Dict[str, List[str]]) -> Dict[str, Set[str]]:\n",
        "    return {\n",
        "        user: set(books)\n",
        "        for user, books in test_user_book.items()\n",
        "        if len(books) > 0\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_predictions(model, users: List[str], k: int):\n",
        "    predictions = {}\n",
        "\n",
        "    for u in tqdm(users, desc=\"Generating Predictions\"):\n",
        "        preds = model.recommend(u, k)\n",
        "        predictions[u] = preds\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41056029"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # -------------------------------\n",
        "    # Paths\n",
        "    # -------------------------------\n",
        "    DATA_FOLDER = \"RokomariBG_Dataset/\"\n",
        "    USER_TO_REVIEW = DATA_FOLDER+\"user_to_review.json\"\n",
        "    BOOK_TO_REVIEW = DATA_FOLDER+\"book_to_review.json\"\n",
        "\n",
        "    K = 10\n",
        "\n",
        "    # -------------------------------\n",
        "    # Build user-book interactions\n",
        "    # -------------------------------\n",
        "    user_book = build_user_book_interactions(\n",
        "        USER_TO_REVIEW,\n",
        "        BOOK_TO_REVIEW,\n",
        "    )\n",
        "\n",
        "    print(f\"Total users with interactions: {len(user_book)}\")\n",
        "\n",
        "    evaluator = RankingEvaluator()\n",
        "\n",
        "    # -------------------------------\n",
        "    # Split 70/15/15\n",
        "    # -------------------------------\n",
        "    train_user_book, val_user_book, test_user_book = split_user_interactions(\n",
        "        user_book\n",
        "    )\n",
        "\n",
        "    ground_truth = build_ground_truth(test_user_book)\n",
        "    test_users = list(ground_truth.keys())\n",
        "\n",
        "    print(f\"Users in test set: {len(test_users)}\")\n",
        "\n",
        "    # =====================================================\n",
        "    # IMPLICIT MF (ALS)\n",
        "    # =====================================================\n",
        "\n",
        "    print(\"\\nTraining Implicit MF (ALS)...\")\n",
        "\n",
        "    implicit_mf = ImplicitMFRecommender(\n",
        "        train_user_book=train_user_book,\n",
        "        n_factors=64,\n",
        "        n_iters=20,\n",
        "    )\n",
        "\n",
        "    implicit_mf.fit()\n",
        "\n",
        "    implicit_preds = generate_predictions(implicit_mf, test_users, K)\n",
        "    implicit_metrics = evaluator.evaluate(implicit_preds, ground_truth)\n",
        "\n",
        "    print(\"\\n===== Implicit MF Results =====\")\n",
        "    for m, v in implicit_metrics.items():\n",
        "        print(f\"{m}: {v:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}