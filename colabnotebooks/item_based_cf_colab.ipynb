{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/backlashblitz/Bangla-Book-Recommendation-Dataset/blob/main/colabnotebooks/item_based_cf_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31793759",
      "metadata": {
        "id": "31793759"
      },
      "source": [
        "# Item-Based Collaborative Filtering\n",
        "**Bangla Book Recommendation Dataset**\n",
        "\n",
        "â–¶ï¸ **Just click `Runtime â†’ Run all` to get started!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46734765",
      "metadata": {
        "id": "46734765"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Install dependencies\n",
        "# ============================================================\n",
        "import os\n",
        "os.system(\"pip install -q huggingface_hub tqdm scikit-learn scipy\")\n",
        "print(\"âœ… Packages installed!\")\n",
        "\n",
        "# ============================================================\n",
        "# Download dataset from HuggingFace\n",
        "# ============================================================\n",
        "import os, shutil\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "REPO_ID = \"DevnilMaster1/Bangla-Book-Recommendation-Dataset\"\n",
        "DATA_FOLDER = \"RokomariBG_Dataset\"\n",
        "os.makedirs(DATA_FOLDER, exist_ok=True)\n",
        "\n",
        "FILES_NEEDED = ['user_to_review.json', 'book_to_review.json']\n",
        "\n",
        "for filename in FILES_NEEDED:\n",
        "    dest = os.path.join(DATA_FOLDER, filename)\n",
        "    if os.path.exists(dest):\n",
        "        print(f\"âœ… Already downloaded: {filename}\")\n",
        "    else:\n",
        "        print(f\"â¬‡ï¸  Downloading {filename} ...\")\n",
        "        downloaded_path = hf_hub_download(\n",
        "            repo_id=REPO_ID,\n",
        "            filename=filename,\n",
        "            repo_type=\"dataset\",\n",
        "        )\n",
        "        shutil.copy(downloaded_path, dest)\n",
        "        print(f\"âœ… Saved: {dest}\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ All files ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87721011",
      "metadata": {
        "id": "87721011"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import gzip\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Set\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13058935",
      "metadata": {
        "id": "13058935"
      },
      "outputs": [],
      "source": [
        "# ---------------------------------------\n",
        "# Utility Loader\n",
        "# ---------------------------------------\n",
        "\n",
        "def load_json(path: str):\n",
        "    \"\"\"Supports both plain .json and gzip .json\"\"\"\n",
        "    if path.endswith(\".gz\"):\n",
        "        import gzip\n",
        "        with gzip.open(path, \"rt\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)\n",
        "    else:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            return json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36861510",
      "metadata": {
        "id": "36861510"
      },
      "outputs": [],
      "source": [
        "class ItemBasedCFRecommender():\n",
        "    \"\"\"\n",
        "    Item-based kNN Collaborative Filtering using SPARSE cosine similarity.\n",
        "    Trained only on train_user_book interactions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, train_user_book: Dict[str, List[str]], k_neighbors: int = 50):\n",
        "        self.train_user_book = {u: list(set(books)) for u, books in train_user_book.items()}\n",
        "        self.k_neighbors = k_neighbors\n",
        "\n",
        "        self.user_ids = []\n",
        "        self.book_ids = []\n",
        "        self.user_id_map = {}\n",
        "        self.book_id_map = {}\n",
        "        self.interaction_matrix = None\n",
        "        self.item_sim_matrix = None\n",
        "\n",
        "    def fit(self):\n",
        "        print(\"Building Item-Based CF (Sparse, train-only)...\")\n",
        "\n",
        "        user_book = self.train_user_book\n",
        "\n",
        "        self.user_ids = sorted(user_book.keys())\n",
        "        self.book_ids = sorted({b for books in user_book.values() for b in books})\n",
        "\n",
        "        self.user_id_map = {u: i for i, u in enumerate(self.user_ids)}\n",
        "        self.book_id_map = {b: i for i, b in enumerate(self.book_ids)}\n",
        "\n",
        "        # Build sparse interaction matrix\n",
        "        rows, cols = [], []\n",
        "        print(\"Building sparse interaction matrix...\")\n",
        "        for u, books in tqdm(user_book.items()):\n",
        "            ui = self.user_id_map[u]\n",
        "            for b in books:\n",
        "                bi = self.book_id_map[b]\n",
        "                rows.append(ui)\n",
        "                cols.append(bi)\n",
        "\n",
        "        data = np.ones(len(rows), dtype=np.float32)\n",
        "        self.interaction_matrix = csr_matrix(\n",
        "            (data, (rows, cols)),\n",
        "            shape=(len(self.user_ids), len(self.book_ids)),\n",
        "        )\n",
        "\n",
        "        # Item-item cosine similarity\n",
        "        print(\"Computing item-item similarity (this may take 5â€“15 minutes)...\")\n",
        "        self.item_sim_matrix = cosine_similarity(\n",
        "            self.interaction_matrix.T, dense_output=False\n",
        "        )\n",
        "\n",
        "    def recommend(self, user_id: str, k: int = 10):\n",
        "        if user_id not in self.user_id_map:\n",
        "            return []\n",
        "\n",
        "        uidx = self.user_id_map[user_id]\n",
        "        user_vector = self.interaction_matrix.getrow(uidx)\n",
        "\n",
        "        scores = np.zeros(len(self.book_ids), dtype=np.float32)\n",
        "        interacted_items = user_vector.indices\n",
        "\n",
        "        for item_idx in interacted_items:\n",
        "            sim_vec = self.item_sim_matrix.getrow(item_idx).toarray().ravel()\n",
        "            neighbors = np.argsort(sim_vec)[::-1][1 : self.k_neighbors + 1]\n",
        "            scores[neighbors] += sim_vec[neighbors]\n",
        "\n",
        "        # Filter out items already seen in TRAIN\n",
        "        scores[interacted_items] = -1\n",
        "\n",
        "        top_items = np.argsort(scores)[::-1][:k]\n",
        "        return [self.book_ids[i] for i in top_items]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43411754",
      "metadata": {
        "id": "43411754"
      },
      "outputs": [],
      "source": [
        "class RankingEvaluator:\n",
        "    \"\"\"\n",
        "    Evaluates ranking-based recommendation metrics.\n",
        "    Computes: Hit@K, MRR@K, NDCG@K for various K values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def hit_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        Hit@K: 1 if at least one relevant item is in top-K, else 0\n",
        "        \"\"\"\n",
        "        top_k = predictions[:k]\n",
        "        return 1.0 if any(item in ground_truth for item in top_k) else 0.0\n",
        "\n",
        "    def mrr_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        MRR@K: Reciprocal rank of first relevant item in top-K\n",
        "        \"\"\"\n",
        "        top_k = predictions[:k]\n",
        "        for rank, item in enumerate(top_k, start=1):\n",
        "            if item in ground_truth:\n",
        "                return 1.0 / rank\n",
        "        return 0.0\n",
        "\n",
        "    def dcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        DCG@K: Discounted Cumulative Gain\n",
        "        \"\"\"\n",
        "        dcg = 0.0\n",
        "        top_k = predictions[:k]\n",
        "        for rank, item in enumerate(top_k, start=1):\n",
        "            if item in ground_truth:\n",
        "                dcg += 1.0 / np.log2(rank + 1)\n",
        "        return dcg\n",
        "\n",
        "    def idcg_at_k(self, ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        IDCG@K: Ideal DCG (best possible DCG)\n",
        "        \"\"\"\n",
        "        ideal_k = min(len(ground_truth), k)\n",
        "        idcg = sum(1.0 / np.log2(rank + 1) for rank in range(1, ideal_k + 1))\n",
        "        return idcg\n",
        "\n",
        "    def ndcg_at_k(self, predictions: List[str], ground_truth: Set[str], k: int) -> float:\n",
        "        \"\"\"\n",
        "        NDCG@K: Normalized Discounted Cumulative Gain\n",
        "        \"\"\"\n",
        "        dcg = self.dcg_at_k(predictions, ground_truth, k)\n",
        "        idcg = self.idcg_at_k(ground_truth, k)\n",
        "\n",
        "        if idcg == 0.0:\n",
        "            return 0.0\n",
        "\n",
        "        return dcg / idcg\n",
        "\n",
        "    def evaluate(self, predictions: Dict[str, List[str]], ground_truth: Dict[str, Set[str]]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate predictions against ground truth.\n",
        "\n",
        "        Args:\n",
        "            predictions: Dict mapping user_id -> list of recommended item_ids (ranked)\n",
        "            ground_truth: Dict mapping user_id -> set of relevant item_ids\n",
        "\n",
        "        Returns:\n",
        "            Dict of metric_name -> average_score\n",
        "        \"\"\"\n",
        "        metrics = {\n",
        "            'Hit@5': [],\n",
        "            'Hit@10': [],\n",
        "            'Hit@50': [],\n",
        "            'MRR@10': [],\n",
        "            'NDCG@10': [],\n",
        "            'NDCG@50': []\n",
        "        }\n",
        "\n",
        "        # Only evaluate users present in both predictions and ground_truth\n",
        "        common_users = set(predictions.keys()) & set(ground_truth.keys())\n",
        "\n",
        "        for user_id in common_users:\n",
        "            preds = predictions[user_id]\n",
        "            gt = ground_truth[user_id]\n",
        "\n",
        "            # Skip users with no ground truth items\n",
        "            if len(gt) == 0:\n",
        "                continue\n",
        "\n",
        "            # Compute metrics\n",
        "            metrics['Hit@5'].append(self.hit_at_k(preds, gt, 5))\n",
        "            metrics['Hit@10'].append(self.hit_at_k(preds, gt, 10))\n",
        "            metrics['Hit@50'].append(self.hit_at_k(preds, gt, 50))\n",
        "            metrics['MRR@10'].append(self.mrr_at_k(preds, gt, 10))\n",
        "            metrics['NDCG@10'].append(self.ndcg_at_k(preds, gt, 10))\n",
        "            metrics['NDCG@50'].append(self.ndcg_at_k(preds, gt, 50))\n",
        "\n",
        "        # Average across all users\n",
        "        results = {}\n",
        "        for metric_name, values in metrics.items():\n",
        "            if len(values) > 0:\n",
        "                results[metric_name] = np.mean(values)\n",
        "            else:\n",
        "                results[metric_name] = 0.0\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89126848",
      "metadata": {
        "id": "89126848"
      },
      "outputs": [],
      "source": [
        "def build_user_book_interactions(\n",
        "    user_to_review_path: str,\n",
        "    book_to_review_path: str,\n",
        ") -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Builds:\n",
        "        user_id -> [book_id, book_id, ...]\n",
        "    \"\"\"\n",
        "    user_to_review = load_json(user_to_review_path)\n",
        "    book_to_review = load_json(book_to_review_path)\n",
        "\n",
        "    # Normalize IDs to string\n",
        "    review_to_user = {\n",
        "        str(x[\"review_id\"]): str(x[\"user_id\"])\n",
        "        for x in user_to_review\n",
        "    }\n",
        "\n",
        "    review_to_book = {\n",
        "        str(x[\"review_id\"]): str(x[\"book_id\"])\n",
        "        for x in book_to_review\n",
        "    }\n",
        "\n",
        "    user_book = defaultdict(list)\n",
        "\n",
        "    for rid, user_id in review_to_user.items():\n",
        "        if rid in review_to_book:\n",
        "            book_id = review_to_book[rid]\n",
        "            user_book[user_id].append(book_id)\n",
        "\n",
        "    return user_book\n",
        "\n",
        "\n",
        "def split_user_interactions(\n",
        "    user_book: Dict[str, List[str]],\n",
        "    seed: int = 42,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        train_user_book\n",
        "        val_user_book\n",
        "        test_user_book\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "\n",
        "    train = {}\n",
        "    val = {}\n",
        "    test = {}\n",
        "\n",
        "    for user, books in user_book.items():\n",
        "        books = list(set(books))  # remove duplicates\n",
        "        random.shuffle(books)\n",
        "\n",
        "        n = len(books)\n",
        "        if n < 3:\n",
        "            train[user] = books\n",
        "            val[user] = []\n",
        "            test[user] = []\n",
        "            continue\n",
        "\n",
        "        n_train = int(0.7 * n)\n",
        "        n_val = int(0.15 * n)\n",
        "\n",
        "        train[user] = books[:n_train]\n",
        "        val[user] = books[n_train : n_train + n_val]\n",
        "        test[user] = books[n_train + n_val :]\n",
        "\n",
        "    return train, val, test\n",
        "\n",
        "\n",
        "def build_ground_truth(test_user_book: Dict[str, List[str]]) -> Dict[str, Set[str]]:\n",
        "    return {\n",
        "        user: set(books)\n",
        "        for user, books in test_user_book.items()\n",
        "        if len(books) > 0\n",
        "    }\n",
        "\n",
        "\n",
        "def generate_predictions(model, users: List[str], k: int):\n",
        "    predictions = {}\n",
        "\n",
        "    for u in tqdm(users, desc=\"Generating Predictions\"):\n",
        "        preds = model.recommend(u, k)\n",
        "        predictions[u] = preds\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31353784",
      "metadata": {
        "id": "31353784"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # -------------------------------\n",
        "    # Paths\n",
        "    # -------------------------------\n",
        "    DATA_FOLDER = \"RokomariBG_Dataset/\"\n",
        "    USER_TO_REVIEW = DATA_FOLDER+\"user_to_review.json\"\n",
        "    BOOK_TO_REVIEW = DATA_FOLDER+\"book_to_review.json\"\n",
        "\n",
        "    K = 10\n",
        "\n",
        "    # -------------------------------\n",
        "    # Build user-book interactions\n",
        "    # -------------------------------\n",
        "    user_book = build_user_book_interactions(\n",
        "        USER_TO_REVIEW,\n",
        "        BOOK_TO_REVIEW,\n",
        "    )\n",
        "\n",
        "    print(f\"Total users with interactions: {len(user_book)}\")\n",
        "\n",
        "    evaluator = RankingEvaluator()\n",
        "\n",
        "    # -------------------------------\n",
        "    # Split 70/15/15\n",
        "    # -------------------------------\n",
        "    train_user_book, val_user_book, test_user_book = split_user_interactions(\n",
        "        user_book\n",
        "    )\n",
        "\n",
        "    ground_truth = build_ground_truth(test_user_book)\n",
        "    test_users = list(ground_truth.keys())\n",
        "\n",
        "    print(f\"Users in test set: {len(test_users)}\")\n",
        "\n",
        "    # =====================================================\n",
        "    # ITEM-BASED CF\n",
        "    # =====================================================\n",
        "\n",
        "    print(\"\\nTraining Item-Based CF...\")\n",
        "\n",
        "    item_cf = ItemBasedCFRecommender(\n",
        "        train_user_book=train_user_book,\n",
        "        k_neighbors=50,\n",
        "    )\n",
        "    item_cf.fit()\n",
        "\n",
        "    item_cf_preds = generate_predictions(item_cf, test_users, K)\n",
        "    item_cf_metrics = evaluator.evaluate(item_cf_preds, ground_truth)\n",
        "\n",
        "    print(\"\\n===== Item-Based CF Results =====\")\n",
        "    for m, v in item_cf_metrics.items():\n",
        "        print(f\"{m}: {v:.4f}\")\n",
        "\n",
        "\n",
        "main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}